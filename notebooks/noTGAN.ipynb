{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from src.utils import one_hot_encoding, plotROCCurves\n",
    "from src.classes import gaussian_copula, variational_autoencoder, ctgan_model\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-application",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(df, categorical, target):\n",
    "    # Train Test Split\n",
    "    X_train, X_test = train_test_split(df, random_state=0, test_size=0.25, stratify=df[target])\n",
    "    X_test, y_test = X_test.drop(columns=[target]), X_test[target]\n",
    "    X_test = one_hot_encoding(X_test, categorical)\n",
    "    \n",
    "    # Initialize data augmentations\n",
    "    copula = gaussian_copula(X_train, categorical, target)\n",
    "    vae = variational_autoencoder(X_train, categorical, target)\n",
    "    ctgan = ctgan_model(X_train, categorical, target)\n",
    "    algos_augment = [copula, vae, ctgan]\n",
    "    \n",
    "    # Initialize classification\n",
    "    algos_classify = [RandomForestClassifier, LogisticRegression, XGBClassifier]\n",
    "    \n",
    "    # Baseline SMOTE\n",
    "    X_train[target] = X_train[target].astype(str)\n",
    "    X_train_smote, y_train_smote = SMOTE(k_neighbors=4).fit_resample(one_hot_encoding(X_train.drop(columns=[target]), categorical), \n",
    "                                                        X_train[target])\n",
    "    \n",
    "    # Baseline NO AUGMENTATION\n",
    "    X_train_baseline, y_train_baseline = one_hot_encoding(X_train.drop(columns=[target]), categorical), X_train[target]\n",
    "    \n",
    "    # Augment\n",
    "    res = dict()\n",
    "    for algo in algos_augment:\n",
    "        print(\"#######\", type(algo).__name__, '########')\n",
    "        algo.fit()\n",
    "        X_train_augmented = algo.augment()\n",
    "        X_train_bis = one_hot_encoding(X_train_augmented.drop(columns=[target]), categorical).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        y_train_bis = X_train_augmented[target]\n",
    "\n",
    "        # Classify\n",
    "        for algo_classify in algos_classify:\n",
    "\n",
    "            ### With augmentation\n",
    "            instance_algo_classify = algo_classify(random_state=0)\n",
    "            instance_algo_classify.fit(X_train_bis, y_train_bis)\n",
    "            y_pred_test = instance_algo_classify.predict(X_test)\n",
    "            perf = f1_score(y_test.astype(str), y_pred_test.astype(str), average=\"macro\")\n",
    "            algo_augment_name = type(algo).__name__\n",
    "            algo_classify_name = type(instance_algo_classify).__name__\n",
    "            try:\n",
    "                res[algo_augment_name][algo_classify_name] = perf\n",
    "            except:\n",
    "                res[algo_augment_name] = dict()\n",
    "                res[algo_augment_name][algo_classify_name] = perf\n",
    "            plotROCCurves(y_test, X_test, instance_algo_classify, algo_augment_name)\n",
    "            print(\"#######\", type(instance_algo_classify).__name__, '########')\n",
    "            print(perf)\n",
    "            print(classification_report(y_test.astype(str), y_pred_test.astype(str)))\n",
    "\n",
    "            ### With SMOTE\n",
    "            instance_algo_classify = algo_classify(random_state=0)\n",
    "            instance_algo_classify.fit(X_train_smote, y_train_smote)\n",
    "            y_pred_test_smote = instance_algo_classify.predict(X_test)\n",
    "            perf = f1_score(y_test.astype(str), y_pred_test_smote.astype(str), average=\"macro\")\n",
    "            try:\n",
    "                res[\"SMOTE\"][algo_classify_name] = perf\n",
    "            except:\n",
    "                res[\"SMOTE\"] = dict()\n",
    "                res[\"SMOTE\"][algo_classify_name] = perf\n",
    "            plotROCCurves(y_test, X_test, instance_algo_classify, \"SMOTE\")\n",
    "            print(\"#######\", \"SMOTE\", '########')\n",
    "            print(perf)\n",
    "            print(classification_report(y_test.astype(str), y_pred_test_smote.astype(str)))\n",
    "            \n",
    "            ### BASELINE\n",
    "            instance_algo_classify = algo_classify(random_state=0)\n",
    "            instance_algo_classify.fit(X_train_baseline, y_train_baseline)\n",
    "            y_pred_test_baseline = instance_algo_classify.predict(X_test)\n",
    "            perf = f1_score(y_test.astype(str), y_pred_test_baseline.astype(str), average=\"macro\")\n",
    "            try:\n",
    "                res[\"BASELINE\"][algo_classify_name] = perf\n",
    "            except:\n",
    "                res[\"BASELINE\"] = dict()\n",
    "                res[\"BASELINE\"][algo_classify_name] = perf\n",
    "            plotROCCurves(y_test, X_test, instance_algo_classify, \"BASELINE\")\n",
    "            print(\"#######\", \"BASELINE\", '########')\n",
    "            print(perf)\n",
    "            print(classification_report(y_test.astype(str), y_pred_test_baseline.astype(str)))\n",
    "            \n",
    "                \n",
    "    return pd.DataFrame.from_dict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoteTime(df, categorical, target):\n",
    "    X_train, X_test = train_test_split(df, random_state=0, test_size=0.25, stratify=df[target])\n",
    "    X_train[target] = X_train[target].astype(str)\n",
    "    beg = time.time()\n",
    "    X_train_smote, y_train_smote = SMOTE(k_neighbors=4).fit_resample(one_hot_encoding(X_train.drop(columns=[target]), categorical), \n",
    "                                                        X_train[target])\n",
    "    end = time.time()\n",
    "    print(\"time:\", end-beg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-gateway",
   "metadata": {},
   "source": [
    "# Contraceptive Method Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cmc = pd.read_csv(\"datasets/low_dimension/cmc.data\")\n",
    "df_cmc.columns = [\"wife_age\", \"wife_education\", \"husband_education\", \"children\", \n",
    "              \"wife_religion\", \"wife_working\", \"husband_occupation\", \"living_index\", \"media\", \"contraceptive\"]\n",
    "categorical = [\"wife_education\", \"husband_education\", \"wife_religion\", \"wife_working\", \"husband_occupation\",\n",
    "              \"living_index\", \"contraceptive\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteTime(df_cmc, categorical, target=\"contraceptive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-circular",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "res_cmc = get_results(df_cmc, categorical, target=\"contraceptive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cmc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-picking",
   "metadata": {},
   "source": [
    "# Yeasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yeast = pd.read_csv(\"datasets/low_dimension/yeast.data\")\n",
    "dic_yeast = {}\n",
    "for i in range(df_yeast.shape[0]):\n",
    "    dic_yeast[i] = df_yeast.iloc[i, 0].split()\n",
    "df_yeast = pd.DataFrame.from_dict(dic_yeast).T\n",
    "df_yeast.columns = [\"sequence_name\", \"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\", \"target\"]\n",
    "df_yeast.drop(columns=[\"sequence_name\"], inplace=True)\n",
    "df_yeast[[\"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\"]] = df_yeast[[\"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\"]].astype(float)\n",
    "categorical = [\"target\"]\n",
    "#Remove ERL\n",
    "df_yeast = df_yeast[df_yeast.target != \"ERL\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteTime(df_yeast, categorical, target=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-river",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "res_yeast = get_results(df_yeast, categorical, target=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_yeast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-hunger",
   "metadata": {},
   "source": [
    "# Arythmia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ary = pd.read_csv(\"datasets/high_dimension/arrhythmia.data\", header=None)\n",
    "df_ary.rename({279:'target'}, inplace=True, axis=1)\n",
    "categorical = [\"target\"]\n",
    "df_ary = df_ary.replace('?', np.NaN)\n",
    "df_ary.iloc[:, 10:15] = df_ary.iloc[:, 10:15].astype(float)\n",
    "df_ary.fillna(df_ary.mean(), inplace=True)\n",
    "df_ary = df_ary[~df_ary.target.isin([\"7\", \"8\", \"9\", \"14\", \"15\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteTime(df_ary, categorical, target=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-encounter",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "res_ary = get_results(df_ary, categorical, target=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-priest",
   "metadata": {},
   "source": [
    "# Covertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cov = pd.read_csv(\"datasets/high_dimension/covertype_csv.csv\")\n",
    "categorical = [\"class\"]\n",
    "_, df_cov = train_test_split(df_cov, random_state=0, test_size=0.10, stratify=df_cov['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteTime(df_cov, categorical, target=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-blocking",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "res_cov = get_results(df_cov, categorical, target=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-authentication",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research bis",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
